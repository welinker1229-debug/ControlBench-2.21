import torch
import dgl
import json
import os
import numpy as np
from sentence_transformers import SentenceTransformer
from transformers import pipeline
from tqdm import tqdm

# ==========================================
# ğŸ”§ å…¨å±€é…ç½® (å­¦æœ¯è§„èŒƒç‰ˆ)
# ==========================================
CONFIG = {
    'bart_model': 'facebook/bart-large-mnli',
    'qwen_model': 'Alibaba-NLP/gte-Qwen2-1.5B-instruct',
    'device': 0 if torch.cuda.is_available() else -1,
    'batch_size': 16,

    # ğŸŒŸ æ ¸å¿ƒç­–ç•¥: ç½®ä¿¡åº¦å¢å¼º (Confidence Boosting)
    # æ›¿ä»£ç¡¬è§„åˆ™: å¦‚æœ BART æåº¦ç¡®ä¿¡(>0.9)ï¼Œåˆ™è§†ä¸º"é“å¾‹"
    'conf_threshold_high': 0.90,
    'weight_boost': 2.0,  # é«˜ç½®ä¿¡åº¦æ ·æœ¬æƒé‡ç¿»å€
    'conf_threshold_low': 0.60,  # ä½ç½®ä¿¡åº¦æ ·æœ¬è§†ä¸ºå™ªéŸ³
    'weight_noise': 0.1  # å™ªéŸ³æ ·æœ¬ç»™äºˆæä½æƒé‡
}


def load_edge_data(topic, data_dir='data'):
    print(f"\n{'=' * 70}")
    print(f"ğŸ§  [Dataset] æ„å»ºæ•°æ®é›†: {topic.upper()}")
    print(f"ğŸ”¥ ç­–ç•¥: çº¯æ•°æ®é©±åŠ¨ (Data-Driven) | å»é™¤äººå·¥è§„åˆ™ | ç½®ä¿¡åº¦åŠ æƒ")
    print(f"{'=' * 70}")

    # 1. è·¯å¾„å…¼å®¹å¤„ç†
    file_path = os.path.join(data_dir, f'graph_data_{topic}.json')
    if not os.path.exists(file_path):
        possible_path = os.path.join('jzhu1905/controbench/controbench-2bc4d0e4076a80cee47529fd4e3c4e4281ead067/data',
                                     f'graph_data_{topic}.json')
        if os.path.exists(possible_path):
            file_path = possible_path
        else:
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")

    # 2. è¯»å–æ•°æ®
    with open(file_path, "r", encoding='utf-8') as f:
        data_json = json.load(f)

    raw_edges = data_json.get('edges', data_json.get('interactions', []))

    # 3. æå–æœ‰æ•ˆäº¤äº’ & æ¸…æ´—
    # å»ºç«‹ Post -> Author æ˜ å°„
    post_author_map = {e['target']: e['source'] for e in raw_edges if
                       e.get('type') == 'user_publish_post' and 'source' in e}

    valid_interactions = []
    valid_texts = []  # æš‚å­˜æ–‡æœ¬ç”¨äºæ‰¹é‡å¤„ç†

    print("-> æ­£åœ¨åˆå§‹åŒ–æ•°æ®å¹¶æ¸…æ´—æ—§æ ‡ç­¾...")
    for edge in raw_edges:
        src = edge.get('source')
        tgt = edge.get('target')
        etype = edge.get('type')
        content = edge.get('content', "") or edge.get('reply_content', "")

        if not content: continue

        real_target = None
        if etype == 'user_comment_user':
            real_target = tgt
        elif etype == 'user_comment_post' and tgt in post_author_map:
            real_target = post_author_map[tgt]
            if src == real_target: continue

        if src and real_target:
            edge['temp_source_id'] = src
            edge['temp_target_id'] = real_target
            edge['temp_content'] = content

            # ğŸ”¥ å¼ºåˆ¶æ¸…é™¤æ—§æ ‡ç­¾ï¼Œç¡®ä¿å®Œå…¨ç”± BART é‡æ–°æ‰“æ ‡
            if 'edge_label' in edge: del edge['edge_label']
            if 'confidence' in edge: del edge['confidence']

            valid_interactions.append(edge)
            valid_texts.append(content[:256])  # æˆªæ–­é˜²æ­¢OOM

    print(f"âœ… å¾…å¤„ç†æ•°æ®: {len(valid_interactions)} æ¡")

    # =================================================
    # ğŸ‘©â€âš–ï¸ Teacher Model: BART-Large (çº¯çŸ¥è¯†è’¸é¦)
    # =================================================
    print(f"ğŸ”¨ å¯åŠ¨ BART-Large (Teacher)...")
    try:
        classifier = pipeline("zero-shot-classification",
                              model=CONFIG['bart_model'],
                              device=CONFIG['device'])
    except Exception as e:
        print(f"âš ï¸ GPUåŠ è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°CPU: {e}")
        classifier = pipeline("zero-shot-classification",
                              model=CONFIG['bart_model'],
                              device=-1)

    # å®šä¹‰åŠ¨æ€æ ‡ç­¾ (ä¸å†éœ€è¦ check_hard_logic)
    topic_labels_map = {
        "lgbtq": ["anti-lgbtq rights", "neutral statement", "pro-lgbtq rights"],
        "abortion": ["anti-abortion", "neutral statement", "pro-choice"],
        "trump": ["anti-trump", "neutral statement", "pro-trump"],
    }
    # é»˜è®¤å›é€€
    current_labels = topic_labels_map.get(topic, [f"opposing {topic}", "neutral", f"supporting {topic}"])

    # æ ‡ç­¾å­—ç¬¦ä¸² -> æ•°å­—ç´¢å¼• (0, 1, 2)
    # æ³¨æ„: BART è¾“å‡ºçš„ label é¡ºåºæ˜¯ä¸å®šçš„ï¼Œéœ€è¦æŸ¥è¡¨
    label_str_to_idx = {
        current_labels[0]: 0,  # Oppose
        current_labels[1]: 1,  # Neutral
        current_labels[2]: 2  # Support
    }

    print(f"-> æ­£åœ¨è¿›è¡Œ Knowledge Distillation (Batch Size: {CONFIG['batch_size']})...")

    high_conf_count = 0
    low_conf_count = 0

    for i in tqdm(range(0, len(valid_interactions), CONFIG['batch_size'])):
        batch_texts = valid_texts[i: i + CONFIG['batch_size']]
        batch_edges = valid_interactions[i: i + CONFIG['batch_size']]

        try:
            # Zero-Shot æ¨ç†
            results = classifier(batch_texts, current_labels, multi_label=False)
        except:
            # å®¹é”™å¤„ç†
            results = [{'labels': [current_labels[1]], 'scores': [0.5]} for _ in batch_texts]

        for edge, res in zip(batch_edges, results):
            top_label_str = res['labels'][0]
            score = res['scores'][0]

            # 1. ç¡®å®šæ ‡ç­¾
            label_idx = label_str_to_idx.get(top_label_str, 1)  # é»˜è®¤ä¸­ç«‹
            edge['edge_label'] = label_idx

            # 2. ç¡®å®šæƒé‡ (Confidence Boosting)
            # è¿™æ˜¯æ›¿ä»£ç¡¬è§„åˆ™çš„å…³é”®é€»è¾‘
            if score > CONFIG['conf_threshold_high']:
                # æƒ…å†µ A: Teacher éå¸¸ç¡®ä¿¡ -> è§†ä¸º"ä¼ªé‡‘æ ‡" -> æƒé‡ç¿»å€
                final_weight = score * CONFIG['weight_boost']
                high_conf_count += 1
            elif score < CONFIG['conf_threshold_low']:
                # æƒ…å†µ B: Teacher çŠ¹è±«ä¸å†³ -> è§†ä¸ºå™ªéŸ³ -> æƒé‡æä½
                final_weight = CONFIG['weight_noise']
                low_conf_count += 1
            else:
                # æƒ…å†µ C: æ™®é€šæ ·æœ¬ -> æƒé‡ç­‰äºç½®ä¿¡åº¦
                final_weight = score

            edge['confidence'] = float(final_weight)

    print(f"ğŸ“Š è’¸é¦ç»Ÿè®¡: é«˜ç½®ä¿¡åº¦å¼ºåŒ–æ ·æœ¬ {high_conf_count} æ¡ | ä½ç½®ä¿¡åº¦é™å™ªæ ·æœ¬ {low_conf_count} æ¡")

    # ä¿å­˜å¤„ç†åçš„æ•°æ® (å¯é€‰ï¼Œæ–¹ä¾¿debug)
    # with open(file_path, "w", encoding='utf-8') as f:
    #     json.dump(data_json, f, ensure_ascii=False)

    # =================================================
    # ğŸš€ Student Model Input: Qwen Embedding
    # =================================================
    print(f"-> ç”Ÿæˆ Qwen Embedding (Student Features)...")
    try:
        text_model = SentenceTransformer(CONFIG['qwen_model'], trust_remote_code=True)
    except Exception as e:
        print(f"âš ï¸ QwenåŠ è½½å¤±è´¥ï¼Œå°è¯• GTE-Base: {e}")
        text_model = SentenceTransformer('Alibaba-NLP/gte-base-en-v1.5', trust_remote_code=True)

    # æ„é€ æŒ‡ä»¤æ–‡æœ¬
    if topic == 'lgbtq':
        task = "Classify the stance of this text regarding LGBTQ rights."
    elif topic == 'abortion':
        task = "Classify the stance of this text regarding Abortion."
    else:
        task = f"Classify the stance regarding {topic}."

    formatted_texts = [f"Instruct: {task}\nQuery: {t}" for t in valid_texts]

    # ç¼–ç 
    feat_tensor = text_model.encode(formatted_texts, convert_to_tensor=True, show_progress_bar=True).cpu()

    # =================================================
    # ğŸ“¦ æ„å»º DGL å›¾
    # =================================================
    # æ˜ å°„ç”¨æˆ· ID
    all_users = set()
    for edge in valid_interactions:
        all_users.add(edge['temp_source_id'])
        all_users.add(edge['temp_target_id'])

    user_map = {uid: i for i, uid in enumerate(all_users)}
    num_nodes = len(user_map)

    src_ids = [user_map[e['temp_source_id']] for e in valid_interactions]
    dst_ids = [user_map[e['temp_target_id']] for e in valid_interactions]

    # æå–æ ‡ç­¾å’Œæƒé‡
    labels_list = [e['edge_label'] for e in valid_interactions]
    weights_list = [e['confidence'] for e in valid_interactions]

    # å»ºå›¾
    g = dgl.heterograph({('user', 'interacts', 'user'): (torch.tensor(src_ids), torch.tensor(dst_ids))},
                        num_nodes_dict={'user': num_nodes})

    # å­˜å…¥æ•°æ®
    g.edges['interacts'].data['feat'] = feat_tensor
    g.edges['interacts'].data['label'] = torch.tensor(labels_list, dtype=torch.long)
    g.edges['interacts'].data['weight'] = torch.tensor(weights_list, dtype=torch.float)

    print(f"âœ… {topic.upper()} æ•°æ®é›†æ„å»ºå®Œæ¯•! (Edges: {g.num_edges()}, Feat Dim: {feat_tensor.shape[1]})")
    return g